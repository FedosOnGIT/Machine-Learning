{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Линейная алгебра"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Многомерное нормальное распределение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$f_{\\mu, \\sum}(x) = \\frac{\\exp(-\\frac{1}{2} \\cdot (x - \\mu)^T \\cdot \\sum^{-1} \\cdot (x - \\mu))}{\\sqrt{(2 \\cdot \\pi)^k \\cdot |\\sum|}}$, где $\\sum$ - матрица ковариации (на диагонали стоит дисперсия), $\\mu$ - вектор смещения.\n",
    "\n",
    "**Генерация точки:**\n",
    "* $\\sum = A^T \\cdot A$\n",
    "* $z_i \\leftarrow \\mathcal{N}(0, 1)$\n",
    "* $x \\leftarrow z_i \\cdot A + \\mu$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"Pics/Dimensions.png\" width=\"500\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Нормализация и извлечение признаков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Декорреляция"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$E(X_j) = 0$\n",
    "\n",
    "*Ковариационная матрица:*\n",
    "\n",
    "$\\Sigma(X) = \\frac{1}{N} \\cdot X^T \\cdot X$\n",
    "\n",
    "*Декорреляция:*\n",
    "\n",
    "$\\bar X = X \\cdot \\Sigma ^ {-\\frac{1}{2}}(X)$\n",
    "\n",
    "$\\Sigma^{\\frac{1}{2}}$ - разложение Холецкого\n",
    "\n",
    "$\\Sigma(\\bar X) = I$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"Pics/Ways.png\" width=\"500\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сингулярное разложение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Теорема:**\n",
    "Любая матрица F размера $n \\cdot m$ может быть представлена в виде сингулярного разложения $F = VDU^T$, где\n",
    "* $V = (v_1, ..., v_m)$ - ортогональная матрица ($V^T \\cdot V = I_m)$ размера $n \\cdot m$. $v_j$ - собственные вектора $F \\cdot F^T$\n",
    "* $D = diag(\\sqrt{\\lambda_1}, ..., \\sqrt{\\lambda_m})$, где $\\sqrt{\\lambda_j}$ - сингулярные числа. $\\lambda_j$ - собственное число $F^T \\cdot F$\n",
    "* $U = (u_1, ..., u_m)$ - ортогональная матрица размера $m \\cdot m$. $u_j$ - собственные вектора $F^T \\cdot F$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Интерпретация:**\n",
    "* $V$ - представляет как объекты соответствуют базисным векторам\n",
    "* $D$ - показывает важность каждого базиса\n",
    "* $U$ - как признаки соответствуют базисным векторам (чего бля???)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Метод главных компонент PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* $X = VDU^T$\n",
    "* $\\Sigma = \\frac{1}{n} X^T X = U \\cdot \\frac{D}{n} \\cdot U^T$\n",
    "* $\\Sigma^{\\frac{1}{2}} = U^T \\cdot \\frac{D}{n}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таким образом можно не брать всю матрицу и кучу всяких признаков, а выбрать лишь нужное количество с наибольшим $\\frac{\\sqrt{\\lambda_j}}{n}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Линейная регрессия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Многомерная регрессия:**\n",
    "$f(x, \\theta) = \\sum_{j=1}^m \\theta_j \\cdot f_j(x), \\theta \\in \\mathcal{R}^m$\n",
    "\n",
    "**Ошибка (для MSE):**\n",
    "$L(\\theta, D) = ||F \\cdot \\theta - y||^2 \\rightarrow \\min_{\\theta in \\mathcal{R}^m}$\n",
    "\n",
    "Как мы помним миниумум достигается в $\\frac{\\partial L(\\theta)}{\\partial \\theta} = 2 \\cdot F^T \\cdot (F \\cdot \\theta - y) = 0$, отсюда $\\theta = (F^T \\cdot F)^{-1} \\cdot F^T \\cdot y$\n",
    "\n",
    "**Определения:**\n",
    "$F^+ = (F^T \\cdot F)^{-1} \\cdot F^T$ - *псевдообратная матрица*. Псевдообратная, так как для квадратной $F$ была бы\n",
    "\n",
    "$P_f = F \\cdot F^+$ - *проекционная матрица*.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте научимся находить эти значения:\n",
    "\n",
    "* $F^+ = (UDV^TVDU^T)^{-1}UDV^T) = |V - ортоганальная| = (UD^2U^T)^{-1}UDV^T = UD^{-2}U^{-1}UDV^T = UD^{-1}V^T = \\sum_{j=1}^m \\frac{1}{\\sqrt{\\lambda}} \\cdot u_j \\cdot v_j^T$\n",
    "* $\\theta = F^+ \\cdot y = UD^{-1}V^Ty = \\sum_{j=1}^m \\frac{1}{\\sqrt{\\lambda_j}} \\cdot u_j \\cdot (v_j^T \\cdot y)$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Однако для борьбы с переобучением нам надо также не забывать про регуляризацию (подробнее в 5 лекции). Рассмотрим на примере гребневой регуляризации:\n",
    "\n",
    "* Формула ошибки преобразуется в $L(\\theta, D) = ||F \\cdot \\theta - y|| ^2 + \\tau \\cdot ||\\theta||^2$\n",
    "\n",
    "* Минимум достигается в точке $\\theta = (F^T \\cdot F + \\tau \\cdot I_m)^{-1} \\cdot F^T \\cdot y = U(D^2 + \\tau \\cdot I_m)^{-1} DV^Ty = \\sum_{j=1}^m \\frac{\\sqrt{\\lambda_j}}{\\lambda_j + \\tau}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}